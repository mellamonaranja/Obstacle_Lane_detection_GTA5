{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import deque\n",
    "from scipy.stats import mode\n",
    "from scipy.optimize import curve_fit\n",
    "from PIL import ImageGrab\n",
    "from yolo_model import BoundBox\n",
    "from directkeys import PressKey, ReleaseKey, W, A, S, D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dir = \"images/detection/detect.jpg\"\n",
    "\n",
    "\n",
    "\n",
    "def straight():\n",
    "    PressKey('W')\n",
    "    ReleaseKey('A')\n",
    "    ReleaseKey('D')\n",
    "\n",
    "def left():\n",
    "    PressKey('A')\n",
    "    ReleaseKey('W')\n",
    "    ReleaseKey('D')\n",
    "    ReleaseKey('A')\n",
    "\n",
    "def right():\n",
    "    PressKey('D')\n",
    "    ReleaseKey('A')\n",
    "    ReleaseKey('W')\n",
    "    ReleaseKey('D')\n",
    "\n",
    "def slow_ya_roll():\n",
    "    ReleaseKey('W')\n",
    "    ReleaseKey('A')\n",
    "    ReleaseKey('D')\n",
    "\n",
    "WHITE = (255, 255, 255)\n",
    "YELLOW = (66, 244, 238)\n",
    "GREEN = (80, 220, 60)\n",
    "LIGHT_CYAN = (255, 255, 224)\n",
    "DARK_BLUE = (139, 0, 0)\n",
    "GRAY = (128, 128, 128)\n",
    "BLUE = (255, 0, 0)\n",
    "RED = (0, 0, 255)\n",
    "ORANGE = (0, 165, 255)\n",
    "BLACK = (0, 0, 0)\n",
    "vehicles = [1, 2, 3, 5, 6, 7, 8]\n",
    "animals = [15, 16, 17, 18, 19, 21, 22, 23]\n",
    "humans = [0]\n",
    "obstructions = humans + animals + vehicles\n",
    "classes = [\n",
    "    'Ped', 'bicycle', 'car', 'motorbike', 'aeroplane', 'bus',\n",
    "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign',\n",
    "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse',\n",
    "    'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe',\n",
    "    'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',\n",
    "    'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat',\n",
    "    'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass',\n",
    "    'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana',\n",
    "    'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog',\n",
    "    'pizza', 'donut', 'cake', 'chair', 'sofa', 'pottedplant',\n",
    "    'bed', 'diningtable', 'toilet', 'tvmonitor', 'laptop', 'mouse',\n",
    "    'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
    "    'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
    "    'teddy bear', 'hair drier', 'toothbrush']\n",
    "\n",
    "def create_queue(length=10):\n",
    "    return deque(maxlen=length)\n",
    "\n",
    "def polyfunc(x, a2, a1, a0):\n",
    "    return a2*x*x + a1*x + a0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OBSTACLE(BoundBox):\n",
    "    xmax: int\n",
    "    xmin: int\n",
    "    ymin: int\n",
    "    ymax: int\n",
    "    xmid: int\n",
    "    ymid: int\n",
    "    lane: str\n",
    "    x: int\n",
    "    y: int\n",
    "    tracker = None\n",
    "    position: [int, int]\n",
    "    PERIOD = 4\n",
    "    __count = 0\n",
    "\n",
    "    def __init__(self, box: BoundBox, _id, v_updt=5):\n",
    "        self.col_time: float = 999.0\n",
    "        self._id = _id\n",
    "        self.position_hist = create_queue(v_updt)\n",
    "        self.update_coord(box)\n",
    "        self.update_score(box)\n",
    "        self.velocity = np.zeros((2))\n",
    "        self.score = box.score\n",
    "        self.label = box.label\n",
    "\n",
    "    def update_obstacle(self, dst, fps, n=5): ####\n",
    "        self.position = dst\n",
    "        if self.lane == \"my\":\n",
    "            self.col_time = min(int(dst[1]/(self.velocity[1]+0.001)*18/5), 99)\n",
    "        else:\n",
    "            self.col_time = None\n",
    "        if self.__count > self.position_hist.maxlen:\n",
    "            self.velocity = ((self.position - self.position_hist[0]) * fps / self.position_hist.maxlen * 5/18).astype(int)\n",
    "        self.__count += 1\n",
    "        self.position_hist.append(dst)\n",
    "\n",
    "    def update_coord(self, box):\n",
    "        self.xmax = box.xmax\n",
    "        self.xmin = box.xmin\n",
    "        self.ymin = box.ymin\n",
    "        self.ymax = box.ymax\n",
    "        self.xmid = int((box.xmax + box.xmin) / 2)\n",
    "        self.ymid = int((box.ymax + box.ymin) / 2)\n",
    "        self.position = np.mean(self.position_hist, axis=0)\n",
    "\n",
    "    def update_score(self, box):\n",
    "        self.score = box.score\n",
    "        self.label = box.label\n",
    "\n",
    "    def update_box(self, box):\n",
    "        self.update_coord(box)\n",
    "        self.update_score(box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LANE_HISTORY:\n",
    "    def __init__(self, fps, queue_depth=12, poly_col=np.array([1, 1, 1]), test_points=[300, 500, 700], poly_max_deviation_distance=50, smoothing=10, ploty=np.array([])):\n",
    "        self.fps = fps\n",
    "        self.test_points = np.asarray(test_points)\n",
    "        self.poly_max_deviation_distance = poly_max_deviation_distance\n",
    "        self.lost = False\n",
    "        self.max_lost_count = queue_depth\n",
    "        self.lost_count = self.max_lost_count + 10\n",
    "        self.smoothing = smoothing\n",
    "        self.ploty = ploty\n",
    "        self.leftFit = None\n",
    "        self.rightFit = None\n",
    "        self.leftx = create_queue(self.fps // 4)\n",
    "        self.rightx = create_queue(self.fps // 4)\n",
    "        self.width = None\n",
    "        self.previous_centers = None\n",
    "        self.current_coef = None\n",
    "        self.smoothed_poly = poly_col\n",
    "        self.poly_history = create_queue(queue_depth)\n",
    "        self.y = None\n",
    "        self.x = None\n",
    "        self.appended = 0\n",
    "        self.breached = 0\n",
    "        self.reset = 0\n",
    "        self.curvature = 0\n",
    "        self.centerx = 0\n",
    "        self.lane_offset = 0\n",
    "        self.left_windows = []\n",
    "        self.right_windows = []\n",
    "\n",
    "    def compute_lane_points(self):\n",
    "        self.leftFit = self.previous_centers - self.width // 2\n",
    "        self.rightFit = self.previous_centers + self.width // 2\n",
    "\n",
    "\n",
    "    def compute_curvature(self, alpha, beta):\n",
    "        y_eval = -np.max(self.ploty)\n",
    "        lp = self.smoothed_poly\n",
    "        denominator = np.absolute(2 * lp[0] * (alpha * beta)**2)\n",
    "        if denominator == 0:\n",
    "            print(\"Error: Division by zero in compute_curvature\")\n",
    "            self.curvature = 0  # Assign a default or error value\n",
    "        else:\n",
    "            numerator = (beta**2 + (2 * lp[0] * y_eval * alpha**2 + lp[1] * alpha)**2)**1.5\n",
    "            curvature_value = numerator / denominator\n",
    "            if np.isnan(curvature_value):\n",
    "                print(\"Error: Computed curvature is NaN\")\n",
    "                self.curvature = 0  # Assign a default or error value\n",
    "            else:\n",
    "                self.curvature = int(curvature_value)\n",
    "\n",
    "    def compute_offset(self):\n",
    "        y_eval = -np.max(self.ploty)\n",
    "        lp = self.smoothed_poly\n",
    "        self.lane_offset = lp[0] * y_eval**2 + lp[1] * y_eval + lp[2] - self.centerx\n",
    "\n",
    "        if np.abs(self.lane_offset).all() > self.width // 2:\n",
    "\n",
    "            if self.lane_offset < 0:\n",
    "                print(\"\\n\\rLANE CHANGE TO RIGHT\\033[F\")\n",
    "                self.poly_history = create_queue(self.poly_history.maxlen)\n",
    "                self.leftx = self.rightx\n",
    "                self.rightx = create_queue(length=self.rightx.maxlen)\n",
    "                self.rightx.append(int(np.mean(self.leftx) + self.width))\n",
    "                self.previous_centers = self.previous_centers + self.width\n",
    "            else:\n",
    "                print(\"\\n\\rLANE CHANGE TO LEFT\\033[F\")\n",
    "                self.poly_history = create_queue(self.poly_history.maxlen)\n",
    "                self.rightx = self.leftx\n",
    "                self.leftx = create_queue(length=self.leftx.maxlen)\n",
    "                self.leftx.append(int(np.mean(self.rightx) - self.width))\n",
    "                self.previous_centers = self.previous_centers - self.width\n",
    "        else:\n",
    "            self.leftx.append(self.previous_centers[0] - self.width // 2)\n",
    "            self.rightx.append(self.previous_centers[0] + self.width // 2)\n",
    "        return\n",
    "\n",
    "    def addlane(self, y, x):\n",
    "        status = \"APPENDED | \"\n",
    "        self.y = y\n",
    "        self.x = x\n",
    "\n",
    "        if len(self.x) >= 3 and len(self.y) >= 3:\n",
    "            self.current_coef, _ = curve_fit(polyfunc, self.y, self.x, p0=self.smoothed_poly)\n",
    "        else:\n",
    "            status = \"TOO FEW POINTS | \"\n",
    "            self.current_coef = self.smoothed_poly\n",
    "\n",
    "\n",
    "        if self.lost_count > self.max_lost_count:\n",
    "            status = \"RESET | \"\n",
    "            self.get_smoothed_polynomial()\n",
    "            self.lost = False\n",
    "            self.lost_count = 0\n",
    "            self.reset += 1\n",
    "            return True, status\n",
    "\n",
    "        test_y_smooth = np.asarray(list(map(lambda x: np.polyval(self.smoothed_poly, x), -self.test_points)))\n",
    "        test_y_new = np.asarray(list(map(lambda x: np.polyval(self.current_coef, x), -self.test_points)))\n",
    "        dist = np.absolute(test_y_smooth - test_y_new)\n",
    "        max_dist = dist[np.argmax(dist)]\n",
    "        if max_dist > self.poly_max_deviation_distance:\n",
    "            status = \"BREACHED | \"\n",
    "            self.lost = True\n",
    "            self.lost_count += 1\n",
    "            self.breached += 1\n",
    "            return False, status\n",
    "\n",
    "        self.get_smoothed_polynomial()\n",
    "        self.lost = False\n",
    "        self.lost_count = 0\n",
    "        self.appended += 1\n",
    "        return True, status\n",
    "\n",
    "    def get_smoothed_polynomial(self):\n",
    "        self.poly_history.append(self.current_coef)\n",
    "        all_coeffs = np.asarray(list(self.poly_history))\n",
    "        self.smoothed_poly = np.mean(all_coeffs[-self.smoothing:, :], axis=0)\n",
    "        self.previous_centers = np.asarray([np.polyval(self.smoothed_poly, -x) for x in self.ploty], dtype=int)\n",
    "        self.compute_lane_points()\n",
    "        self.compute_offset()\n",
    "        return self.smoothed_poly\n",
    "\n",
    "    def calculate_position(self, x, y):\n",
    "        position = np.polyval(self.smoothed_poly, y) - x\n",
    "        status = \"right\"\n",
    "        if position < -self.width // 2:\n",
    "            status = \"left\"\n",
    "        elif position < self.width // 2:\n",
    "            status = \"my\"\n",
    "        return status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LANE_DETECTION:\n",
    "    UNWARPED_SIZE: (int, int)\n",
    "    WRAPPED_WIDTH: int\n",
    "    _pip_size = (int, int)\n",
    "    _pip__x_offset = 20\n",
    "    _pip__y_offset = 10\n",
    "    img_dimensions = (int, int)\n",
    "    temp_dir = \"./images/detection/\"\n",
    "    windows_per_line = 30\n",
    "    vanishing_point: (int, int)\n",
    "\n",
    "    # real_world_lane_size_meters = (32, 3.7) ####\n",
    "    real_world_lane_size_meters = (32, 1) ####\n",
    "\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    bottom = 0\n",
    "\n",
    "    def __init__(self, img, fps=30, yellow_lower=(20, 100, 100), yellow_upper=(30, 255, 255),\n",
    "                 white_lower=(0, 0, 200), white_upper=(255, 255, 255), lum_factor=130,\n",
    "                 max_gap_th=2/5, lane_start=[0.35, 0.75], verbose=3): #####\n",
    "\n",
    "        if img is None:\n",
    "            raise ValueError(\"img parameter is None. Please provide a valid image.\")\n",
    "        if not hasattr(img, 'shape'):\n",
    "            raise TypeError(\"img parameter does not have a shape attribute. It might not be a valid image object.\")\n",
    "\n",
    "        self.message = \"\"\n",
    "        self.verbose = verbose\n",
    "        self.objpts = None\n",
    "        self.count = 0\n",
    "        self.fps = int(fps)\n",
    "        self.imgpts = None\n",
    "        self.lane_roi = None\n",
    "        self.yellow_lower = yellow_lower\n",
    "        self.yellow_upper = yellow_upper\n",
    "        self.white_lower = white_lower\n",
    "        self.white_upper = white_upper\n",
    "        self.lane_change = False\n",
    "        self.lum_factor = lum_factor\n",
    "        self.image = img\n",
    "        self.font_sz = 4e-4 * self.image.shape[0]\n",
    "        self.img_dimensions = (self.image.shape[0], self.image.shape[1])\n",
    "\n",
    "        self.UNWARPED_SIZE = (360, 360)\n",
    "        # self.UNWARPED_SIZE = (int(self.img_dimensions[1]*0.5),int(self.img_dimensions[1]*0.5))\n",
    "\n",
    "        self.WRAPPED_WIDTH = int(self.img_dimensions[1] * 0.15) #####\n",
    "        \n",
    "\n",
    "        self.margin = int(self.UNWARPED_SIZE[1] * 0.08) ####\n",
    "\n",
    "\n",
    "        self.window_height = np.array(self.UNWARPED_SIZE[1] // self.windows_per_line).astype(int)\n",
    "        self._pip_size = (int(self.image.shape[1] * 0.2), int(self.image.shape[0] * 0.2))\n",
    "        self.minpix = self.window_height\n",
    "        self.maxpix = int(self.margin * self.window_height * 0.5)\n",
    "        self.n_gap_skip = 0\n",
    "        self.max_gap = 0\n",
    "        self.windows_range = range(self.windows_per_line)\n",
    "        self.window_offset = 0\n",
    "        self.ploty = np.linspace(int(self.UNWARPED_SIZE[1] * 0.45), self.UNWARPED_SIZE[1] - 1, int(self.UNWARPED_SIZE[1] * 0.4), dtype=int)\n",
    "        test = np.arange(0.3, 1, 0.1) * self.UNWARPED_SIZE[1]\n",
    "        test = test.astype(int)\n",
    "        self.lane = LANE_HISTORY(self.fps, test_points=test, queue_depth=self.fps // 3, ploty=self.ploty)\n",
    "        self.max_gap_th = max_gap_th * self.windows_per_line\n",
    "        self.calc_perspective(lane_start=lane_start)\n",
    "\n",
    "    def compute_bounds(self, image):\n",
    "        lx = int(max(np.mean(self.lane.leftx), 0))\n",
    "        rx = int(max(min(np.mean(self.lane.rightx), image.shape[0]), max(image.shape[0] // 4, lx)))\n",
    "        avg = np.average(image[lx:rx, image.shape[1] * 2 // 3: image.shape[1] - self.bottom, 1])\n",
    "        \n",
    "        # l_rel = max(min((avg / self.lum_factor) ** 2, 1.3), 0.45) #####\n",
    "        l_rel = max(min((avg / self.lum_factor) ** 12, 1.3), 0.45) #####\n",
    "\n",
    "        self.yellow_lower[1] = int(l_rel * 30)#####\n",
    "        self.white_lower[1] = int(l_rel * 170)#####\n",
    "        self.message = self.message + \"WHITE\" + str(self.white_lower[1])\n",
    "        return\n",
    "\n",
    "    def compute_mask(self, image):\n",
    "        converted = cv2.cvtColor(image, cv2.COLOR_BGR2HLS)\n",
    "        \n",
    "        if self.count % (self.fps * 4) == 0:\n",
    "            self.compute_bounds(converted)\n",
    "        yellow_mask = cv2.inRange(converted, self.yellow_lower, self.yellow_upper)\n",
    "        white_mask = cv2.inRange(converted, self.white_lower, self.white_upper)\n",
    "        mask = cv2.bitwise_or(white_mask, yellow_mask)\n",
    "        t2 =  cv2.bitwise_and(image, image, mask = mask)\n",
    "        print(self.white_lower[1])\n",
    "        return mask\n",
    "\n",
    "    def calc_perspective(self, lane_start=[0.25, 0.75]): ####\n",
    "        roi = np.zeros((self.img_dimensions[0], self.img_dimensions[1]), dtype=np.uint8)\n",
    "        \n",
    "        # roi_points = np.array([[0, self.img_dimensions[0] * 7 // 9],\n",
    "        #                        [0, self.img_dimensions[0]],\n",
    "        #                        [self.img_dimensions[1], self.img_dimensions[0]],\n",
    "        #                        [self.img_dimensions[1], self.img_dimensions[0] * 7 // 9],\n",
    "        #                        [self.img_dimensions[1] * 45 // 99, self.img_dimensions[0] // 2],\n",
    "        #                        [self.img_dimensions[1] * 45 // 99, self.img_dimensions[0] // 2]], dtype=np.int32)\n",
    "        roi_points = np.array([[\n",
    "        [10,500],[10,300], [300,200], [500,200], [800,300], [800,500]]\n",
    "    ])\n",
    "        \n",
    "        cv2.fillPoly(roi, [roi_points], 255) #1\n",
    "        grey = cv2.cvtColor(self.image, cv2.COLOR_BGR2GRAY)\n",
    "        mn_hsl = np.median(grey)\n",
    "        edges = cv2.Canny(grey, int(mn_hsl), int(mn_hsl * .3))\n",
    "\n",
    "        # lines = cv2.HoughLinesP(edges * roi, rho=self.img_dimensions[0] // 20,\n",
    "        #                         theta=2 * np.pi / 180,\n",
    "        #                         threshold=self.img_dimensions[0] // 80,\n",
    "        #                         minLineLength=self.img_dimensions[0] // 3,\n",
    "        #                         maxLineGap=self.img_dimensions[0] // 15) #####\n",
    "       \n",
    "       \n",
    "        lines = cv2.HoughLinesP(edges * roi, rho=self.img_dimensions[0] // 20,  theta=np.pi/180,  threshold=180, minLineLength=20, maxLineGap=15)\n",
    "        \n",
    "        Lhs = np.zeros((2, 2), dtype=np.float32)\n",
    "        Rhs = np.zeros((2, 1), dtype=np.float32)\n",
    "\n",
    "        img2 =  self.image.copy()\n",
    "        if lines is not None:\n",
    "            for line in lines:\n",
    "                for x1, y1, x2, y2 in line:\n",
    "                    cv2.line(img2, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "                    normal = np.array([[-(y2 - y1)], [x2 - x1]], dtype=np.float32)\n",
    "                    normal /= np.linalg.norm(normal)\n",
    "                    point = np.array([[x1], [y1]], dtype=np.float32)\n",
    "                    outer = np.matmul(normal, normal.T)\n",
    "                    Lhs += outer\n",
    "                    Rhs += np.matmul(outer, point)\n",
    "\n",
    "            self.vanishing_point = np.matmul(np.linalg.pinv(Lhs), Rhs).reshape(2)\n",
    "\n",
    "            orig_points = self.vanishing_point.copy()\n",
    "\n",
    "        else:\n",
    "            print(\"No lines detected\")\n",
    "\n",
    "        if not hasattr(self, 'vanishing_point') or self.vanishing_point is None:\n",
    "            print(\"NO VANISHING POINT DETECTED\")\n",
    "            self.vanishing_point = (self.img_dimensions[1] // 2, self.img_dimensions[0] * 0.57)\n",
    "\n",
    "\n",
    "        else:\n",
    "            # x_threshold = 1.0 * self.img_dimensions[1]  \n",
    "            x_threshold = 0.07 * self.img_dimensions[1] \n",
    "            # x_threshold = 0.01 * self.img_dimensions[1] \n",
    "\n",
    "\n",
    "            if abs(self.vanishing_point[0] - self.img_dimensions[1] // 2) > x_threshold:\n",
    "                print(\"ABSURD X POSITION TRY OTHER PARAMETERS\", self.vanishing_point[0], \"in ==> \", self.img_dimensions)\n",
    "                self.vanishing_point[0] = self.img_dimensions[1] // 2\n",
    "\n",
    "            # y_threshold = 1.0 * self.img_dimensions[0]\n",
    "            # y_threshold = 0.1 * self.img_dimensions[0]\n",
    "            # y_threshold = 0.01 * self.img_dimensions[0]\n",
    "            y_threshold = 0.005 * self.img_dimensions[0]\n",
    "\n",
    "            # if abs(self.vanishing_point[1] - self.img_dimensions[0] // 2) > y_threshold: ####\n",
    "            if abs(self.vanishing_point[1] - self.img_dimensions[0] *0.57) > y_threshold:\n",
    "\n",
    "                print(\"ABSURD Y POSITION TRY OTHER PARAMETERS\", self.vanishing_point[0], \"in ==> \", self.img_dimensions)\n",
    "                \n",
    "                # self.vanishing_point[1] = self.img_dimensions[1] // 2 ####\n",
    "                self.vanishing_point[1] = int(self.img_dimensions[0] *0.57)\n",
    "\n",
    "        self.vanishing_point = tuple(map(int, self.vanishing_point))\n",
    "\n",
    "        orig_points = [(0, 0), (self.img_dimensions[1], 0),\n",
    "                       (self.img_dimensions[1], self.img_dimensions[0]), (0, self.img_dimensions[0])]\n",
    "        self.vanishing_point = tuple(map(int, self.vanishing_point))\n",
    "\n",
    "        orig_points = tuple(tuple(int(coord) for coord in point) for point in orig_points)\n",
    "\n",
    "        top = self.vanishing_point[1] + int(self.WRAPPED_WIDTH * 0.15) ####\n",
    "        # top = self.vanishing_point[1] + int(self.WRAPPED_WIDTH * 0.5) ####\n",
    "\n",
    "        self.bottom = int(0.02 * self.img_dimensions[0]) ####\n",
    "        bottom = self.img_dimensions[0] + self.bottom\n",
    "\n",
    "        def on_line(p1, p2, ycoord):\n",
    "            return [p1[0] + (p2[0] - p1[0]) / float(p2[1] - p1[1]) * (ycoord - p1[1]), ycoord]\n",
    "\n",
    "        p1 = [self.vanishing_point[0] - self.WRAPPED_WIDTH / 2, top]\n",
    "        p2 = [self.vanishing_point[0] + self.WRAPPED_WIDTH / 2, top]\n",
    "        p3 = on_line(p2, self.vanishing_point, bottom)\n",
    "        p4 = on_line(p1, self.vanishing_point, bottom)\n",
    "        src_points = np.array([p1, p2, p3, p4], dtype=np.float32)\n",
    "        dst_points = np.array([[0, 0], [self.UNWARPED_SIZE[0], 0],\n",
    "                               [self.UNWARPED_SIZE[0], self.UNWARPED_SIZE[1]],\n",
    "                               [0, self.UNWARPED_SIZE[1]]], dtype=np.float32)\n",
    "        self.trans_mat = cv2.getPerspectiveTransform(src_points, dst_points)\n",
    "        self.inv_trans_mat = cv2.getPerspectiveTransform(dst_points, src_points)\n",
    "        min_wid = 1000 ####\n",
    "        img = cv2.warpPerspective(self.image, self.trans_mat, self.UNWARPED_SIZE)\n",
    "        x1 = int(self.UNWARPED_SIZE[0] * lane_start[0])\n",
    "        x2 = int(self.UNWARPED_SIZE[0] * lane_start[1])\n",
    "        self.lane.leftx.append(x1)\n",
    "        self.lane.rightx.append(x2)\n",
    "        mask = self.compute_mask(img)\n",
    "        span = self.UNWARPED_SIZE[0] // 5\n",
    "        x1 = x1 - span + self.detect_lane_start(mask[:, x1 - span: x1 + span])\n",
    "        x2 = x2 - span + self.detect_lane_start(mask[:, x2 - span: x2 + span])\n",
    "        self.lane.leftx.append(x1)\n",
    "        self.lane.rightx.append(x2)\n",
    "        self.lane.width = x2 - x1\n",
    "        self.lane.previous_centers = np.ones(self.windows_per_line) * (x1 + x2) // 2\n",
    "        lane_roi_points = np.array([\n",
    "            [self.img_dimensions[1] * 9 // 80, self.img_dimensions[0]],\n",
    "            [self.img_dimensions[1] * 71 // 80, self.img_dimensions[0]],\n",
    "            [self.vanishing_point[0] + 3 * self.img_dimensions[1] // 25, self.vanishing_point[1] - 10],\n",
    "            [self.vanishing_point[0] - 3 * self.img_dimensions[1] // 25, self.vanishing_point[1] - 10]], dtype=np.int32)\n",
    "        cv2.fillPoly(self.lane_roi, [lane_roi_points], 1)\n",
    "\n",
    "        if x2 - x1 < min_wid:\n",
    "            min_wid = x2 - x1\n",
    "        self.px_per_xm = min_wid / self.real_world_lane_size_meters[1]\n",
    "        self.xm_per_px = 1 / self.px_per_xm\n",
    "        try:\n",
    "            Lh = np.linalg.inv(self.trans_mat)\n",
    "        except np.linalg.LinAlgError:\n",
    "            Lh = np.linalg.pinv(self.trans_mat)  # Use pseudo-inverse as a fallback\n",
    "\n",
    "        self.px_per_ym = self.px_per_xm * np.linalg.norm(Lh[:, 0]) / np.linalg.norm(Lh[:, 1])\n",
    "        self.ym_per_px = 1 / self.px_per_ym\n",
    "        self.perspective_done_at = datetime.utcnow().timestamp()\n",
    "\n",
    "        pos = np.array([self.vanishing_point], dtype=np.float32)\n",
    "        pos = np.array(pos, dtype=np.float32)\n",
    "        pos = pos[None, :, :]\n",
    "        dst = cv2.perspectiveTransform(pos, self.trans_mat)\n",
    "        self.lane.centerx = dst[0]\n",
    "        print(\"PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\")\n",
    "        \n",
    "        if self.verbose > 1:\n",
    "            img_orig = cv2.polylines(self.image, [src_points.astype(np.int32)], True, (0, 0, 255), thickness=5)\n",
    "            cv2.line(img, (int(x1), 0), (int(x1), self.UNWARPED_SIZE[1]), (255, 0, 0), 3)\n",
    "            cv2.line(img, (int(x2), 0), (int(x2), self.UNWARPED_SIZE[1]), (0, 0, 255), 3)\n",
    "            cv2.circle(img_orig, tuple(self.vanishing_point), 10, color=RED, thickness=5)\n",
    "            for point in orig_points:\n",
    "                cv2.circle(img_orig, tuple(point[:2]), 10, color=GRAY, thickness=4)\n",
    "            # cv2.imwrite(self.temp_dir + \"vanishing_point_0.01.jpg\", img_orig)\n",
    "            # cv2.imwrite(self.temp_dir + \"vanishing_point_y_0.005.jpg\", img_orig)\n",
    "            # cv2.imwrite(self.temp_dir + \"lane_width_margin_1.08.jpg\", img)\n",
    "            # cv2.imwrite(self.temp_dir + \"perspective_lines.jpg\", img2)\n",
    "            # cv2.imwrite(self.temp_dir + \"mask.jpg\", mask)\n",
    "            # img = cv2.bitwise_and(img, img, mask=mask)\n",
    "            # cv2.imwrite(self.temp_dir + \"masked_regions.jpg\", img)\n",
    "            # cv2.imwrite(self.temp_dir + \"edges.jpg\", edges * roi)\n",
    "            return img_orig\n",
    "        return\n",
    "\n",
    "    def calculate_position(self, box: OBSTACLE):\n",
    "        pos = np.float32(np.array((box.xmax / 2 + box.xmin / 2, box.ymax)).reshape(1, 1, -1))\n",
    "        dst = cv2.perspectiveTransform(pos[None, :, :], self.trans_mat)\n",
    "        box.x = int(dst[0])\n",
    "        box.y = -int(dst[1])\n",
    "        box.lane = self.lane.calculate_position(box.x, box.y)\n",
    "        dst = np.array([dst[0] / self.px_per_xm, (self.UNWARPED_SIZE[1] - dst[1]) / self.px_per_ym])\n",
    "        box.update_obstacle(dst, self.fps)\n",
    "        return box\n",
    "\n",
    "    def put_text(self, overlay, text, coord, color=WHITE):\n",
    "        sz = self.font_sz * 50\n",
    "        rect_ht = int(sz * 1.1)\n",
    "        rect_wd = int(len(text) * sz * 0.5)\n",
    "        p1 = (coord[0], coord[1] + 2)\n",
    "        p2 = (coord[0] + rect_wd, coord[1] - rect_ht)\n",
    "        cv2.rectangle(overlay, p1, p2, (0, 0, 0), -1)\n",
    "        cv2.putText(overlay, text, coord, self.font, self.font_sz * 1.25, color, 1, cv2.LINE_AA)\n",
    "        return\n",
    "\n",
    "    def process_image(self, img, obstacles: [OBSTACLE] = [], alpha=.7, beta=0.3, gamma=0): ####\n",
    "        off = int(100 * self.font_sz)\n",
    "        self.message = \"[\" + str(self.count) + \"]\"\n",
    "        overlay = img.copy()\n",
    "        thres_img_psp = self.compute_lane_lines(overlay)\n",
    "        for i in range(len(obstacles)):\n",
    "            obstacles[i] = self.calculate_position(obstacles[i])\n",
    "            box = obstacles[i]\n",
    "            past = [box.xmin, box.ymin, box.xmax, box.ymax]\n",
    "            color = WHITE\n",
    "            t1 = classes[obstructions[box.label]] + \" [\" + str(int(box.position[1])) + \"m]\"\n",
    "            t2 = \"(\" + str(int(box.score * 100)) + \"%) ID: \" + str(box._id)\n",
    "            b1 = \"Lane \" + box.lane + \" \" + str(int(box.velocity[1])) + \"kmph\"\n",
    "            pt1 = (box.xmin, box.ymin - off)\n",
    "            pt2 = (box.xmin, box.ymin)\n",
    "            pb1 = (box.xmin, box.ymax + off)\n",
    "            if box.lane == \"my\" and box.velocity[1] < 0:\n",
    "                color = RED\n",
    "                if box.col_time > -4:\n",
    "                    b3 = \"Col \" + str(int(box.col_time)) + \"s\"\n",
    "                    pb3 = (box.xmin, box.ymax + 2 * off)\n",
    "                    self.put_text(overlay, b3, pb3, color=color)\n",
    "            self.put_text(overlay, t1, pt1, color=color)\n",
    "            self.put_text(overlay, t2, pt2, color=color)\n",
    "            \n",
    "            self.put_text(overlay, b1, pb1, color=color)\n",
    "            past_center = (int(past[0] / 2 + past[2] / 2), past[3])\n",
    "            color = ORANGE if box.velocity[1] < 0 else GREEN\n",
    "            cv2.rectangle(overlay, (box.xmin, box.ymin), (box.xmax, box.ymax), color, 2)\n",
    "        img = cv2.addWeighted(img, alpha, overlay, beta, gamma)\n",
    "        out_img = np.dstack((thres_img_psp, thres_img_psp, thres_img_psp))\n",
    "        img = self.draw_lane_area(out_img, img)\n",
    "        if self.verbose > 2:\n",
    "            drawn_lines = self.draw_lane_lines(out_img)\n",
    "            drawn_hotspots = self.draw_lines_hotspots(out_img, obstacles)\n",
    "            img = self.combine_images(img, drawn_lines, drawn_hotspots)\n",
    "            img = self.draw_lane_curvature_text(img)\n",
    "\n",
    "        # lane_position = self.lane.lane_offset\n",
    "        # lane_curvature = self.lane.curvature\n",
    "\n",
    "\n",
    "        # if lane_curvature > 1500: ###\n",
    "        #     straight()\n",
    "        # elif (lane_position > 0).any():  # Check if any element in lane_position is greater than 0\n",
    "        #     right()\n",
    "        # elif (lane_position < 0).any():  # Check if any element in lane_position is less than 0\n",
    "        #     left()\n",
    "        # else:\n",
    "        #     slow_ya_roll()\n",
    "\n",
    "        return img\n",
    "\n",
    "        \n",
    "\n",
    "    def draw_lane_curvature_text(self, img):\n",
    "        sz = self.font_sz * 3\n",
    "        offset_y = self._pip_size[1] * 1 + self._pip__y_offset * 5\n",
    "        offset_x = self._pip__x_offset\n",
    "        template = \"{0:17}{1:17}\"\n",
    "        txt_header = template.format(\"Curvature \", \"Offset\")\n",
    "        txt_values = template.format(\"{:d}m\".format(self.lane.curvature),\n",
    "                                    \n",
    "                                    #  \"{:.2f}m Left\".format(self.lane.lane_offset * self.xm_per_px))\n",
    "                                    \"{:.2f}m Left\".format(np.mean(self.lane.lane_offset) * self.xm_per_px))\n",
    "\n",
    "        # if self.lane.lane_offset < 0.0:\n",
    "        #     txt_values = template.format(\"{:d}m\".format(self.lane.curvature),\n",
    "        #                                  \"{:.2f}m Right\".format(self.lane.lane_offset * self.xm_per_px))\n",
    "\n",
    "        if np.any(self.lane.lane_offset < 0.0):\n",
    "            txt_values = template.format(\"{:d}m\".format(self.lane.curvature),\n",
    "                                         \"{:.2f}m Right\".format(np.mean(self.lane.lane_offset) * self.xm_per_px))\n",
    "            \n",
    "        cv2.putText(img, txt_header, (offset_x, offset_y), self.font, sz, BLACK, 1, cv2.LINE_AA)\n",
    "        cv2.putText(img, txt_values, (offset_x, offset_y + self._pip__y_offset * 2), self.font, sz, BLACK, 2, cv2.LINE_AA)\n",
    "        cv2.putText(img, self.message, (offset_x, self.img_dimensions[0] - 10), self.font, sz, BLACK, 1, cv2.LINE_AA)\n",
    "        return img\n",
    "\n",
    "    def combine_images(self, lane_area_img, lines_img, lane_hotspots_img):\n",
    "        small_lines = cv2.resize(lines_img, self._pip_size)\n",
    "        small_hotspots = cv2.resize(lane_hotspots_img, self._pip_size)\n",
    "        lane_area_img[self._pip__y_offset: self._pip__y_offset + self._pip_size[1], self._pip__x_offset: self._pip__x_offset + self._pip_size[0]] = small_lines\n",
    "        start_offset_y = self._pip__y_offset\n",
    "        start_offset_x = 2 * self._pip__x_offset + 1 * self._pip_size[0]\n",
    "        lane_area_img[start_offset_y: start_offset_y + self._pip_size[1], start_offset_x: start_offset_x + self._pip_size[0]] = small_hotspots\n",
    "        return lane_area_img\n",
    "\n",
    "    def draw_lane_area(self, warped_img, undist_img):\n",
    "        color_warp = np.zeros_like(warped_img).astype(np.uint8)\n",
    "        pts_left = np.array([np.transpose(np.vstack([self.lane.leftFit, self.ploty]))])\n",
    "        pts_right = np.array([np.flipud(np.transpose(np.vstack([self.lane.rightFit, self.ploty])))])\n",
    "        pts = np.hstack((pts_left, pts_right))\n",
    "        cv2.fillPoly(color_warp, np.int_([pts]), GREEN)\n",
    "        newwarp = cv2.warpPerspective(color_warp, self.inv_trans_mat, (undist_img.shape[1], undist_img.shape[0]))\n",
    "        result = cv2.addWeighted(undist_img, 1, newwarp, 0.3, 0)\n",
    "        return result\n",
    "\n",
    "    def draw_lane_lines(self, img):\n",
    "        out_img = img.copy()\n",
    "        for low_pt, high_pt in self.lane.left_windows:\n",
    "            cv2.rectangle(out_img, low_pt, high_pt, (0, 255, 0), 1)\n",
    "        for low_pt, high_pt in self.lane.right_windows:\n",
    "            cv2.rectangle(out_img, low_pt, high_pt, (0, 255, 0), 1)\n",
    "        return out_img\n",
    "\n",
    "    def draw_lines_hotspots(self, img, obstacles: [OBSTACLE] = []):\n",
    "        sz = self.font_sz * 12\n",
    "        out_img = img.copy()\n",
    "        lx = self.lane.x - self.lane.width // 2\n",
    "        rx = self.lane.x + self.lane.width // 2\n",
    "        pts_left = np.dstack((self.lane.leftFit, self.ploty)).astype(np.int32)\n",
    "        pts_right = np.dstack((self.lane.rightFit, self.ploty)).astype(np.int32)\n",
    "        pts_cntr = np.dstack((self.lane.rightFit - self.lane.width // 2, self.ploty)).astype(np.int32)\n",
    "        cv2.polylines(out_img, pts_left, False, BLUE, 2)\n",
    "        cv2.polylines(out_img, pts_right, False, RED, 2)\n",
    "        cv2.polylines(out_img, pts_cntr, False, YELLOW, 15)\n",
    "        for i in range(len(obstacles)):\n",
    "            box = obstacles[i]\n",
    "            color = GREEN\n",
    "            if box.col_time and box.lane == \"my\" and box.col_time < 0 and box.col_time > -4:\n",
    "                color = RED\n",
    "            cv2.putText(out_img, str(box._id), (box.x, -box.y), self.font, sz, color, 8, cv2.LINE_AA)\n",
    "        return out_img\n",
    "\n",
    "    def detect_lane_start(self, image):\n",
    "        histx = np.sum(image[image.shape[0] * 4 // 5:, :], axis=0)\n",
    "        return np.argmax(histx)\n",
    "\n",
    "    def compute_lane_lines(self, img):\n",
    "        self.lane.left_windows = []\n",
    "        self.lane.right_windows = []\n",
    "        undst_img = cv2.bitwise_and(img, img, mask=self.lane_roi)\n",
    "        pp_img = cv2.warpPerspective(undst_img, self.trans_mat, (self.UNWARPED_SIZE[1], self.UNWARPED_SIZE[0]))\n",
    "        warped_img = self.compute_mask(pp_img)\n",
    "        x1_av = int(np.average(self.lane.leftx))\n",
    "        x2_av = int(np.average(self.lane.rightx))\n",
    "        self.lane.width = min(max(int(x2_av - x1_av), self.UNWARPED_SIZE[0] // 3), self.UNWARPED_SIZE[0] // 2)\n",
    "        x1 = min(max(x1_av, self.margin), self.UNWARPED_SIZE[0] - self.lane.width)\n",
    "        x2 = max(min(x2_av, self.UNWARPED_SIZE[0] - self.margin - 1), self.lane.width)\n",
    "        leftx_current = x1 - self.margin + self.detect_lane_start(warped_img[:, x1 - self.margin: x1 + self.margin])\n",
    "        rightx_current = x2 - self.margin + self.detect_lane_start(warped_img[:, x2 - self.margin: x2 + self.margin])\n",
    "        nonzero = warped_img.nonzero()\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        centerx_current = (x2_av - x1_av) // 2\n",
    "        pointx = []\n",
    "        pointy = []\n",
    "        center_idx = []\n",
    "        curve_compute = 0\n",
    "        self.max_gap = 0\n",
    "        gap = 0\n",
    "        for window in self.windows_range:\n",
    "            win_y_low = warped_img.shape[0] - (window + 1) * self.window_height\n",
    "            win_y_high = warped_img.shape[0] - window * self.window_height\n",
    "            win_xleft_low = leftx_current - self.margin\n",
    "            win_xleft_high = leftx_current + self.margin\n",
    "            win_xright_low = rightx_current - self.margin\n",
    "            win_xright_high = rightx_current + self.margin\n",
    "            self.lane.left_windows.append([(win_xleft_low, win_y_low), (win_xleft_high, win_y_high)])\n",
    "            good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) &\n",
    "                              (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "            self.lane.right_windows.append([(win_xright_low, win_y_low), (win_xright_high, win_y_high)])\n",
    "            good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) &\n",
    "                               (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "            centerx = np.array([])\n",
    "            centery = np.array([])\n",
    "            s = 0\n",
    "            if len(good_left_inds) > self.minpix and len(good_left_inds) < self.maxpix:\n",
    "                x = mode(nonzerox[good_left_inds])[0]\n",
    "                y = mode(nonzeroy[good_left_inds])[0]\n",
    "                s += 1\n",
    "                centerx = x + self.lane.width // 2\n",
    "                centery = -y\n",
    "            if len(good_right_inds) > self.minpix and len(good_right_inds) < self.maxpix:\n",
    "                s += 1\n",
    "                x = mode(nonzerox[good_right_inds])[0]\n",
    "                y = mode(nonzeroy[good_right_inds])[0]\n",
    "                centerx = np.append(centerx, x - self.lane.width // 2)\n",
    "                centery = np.append(centery, -y)\n",
    "            if s > 0:\n",
    "                centerx_current = int(np.average(centerx))\n",
    "                pointx.append(centerx_current)\n",
    "                pointy.append(int(np.average(centery)))\n",
    "                gap = 0\n",
    "            else:\n",
    "                gap += 1\n",
    "                if len(center_idx) > 5:\n",
    "                    if curve_compute % 5 == 0:\n",
    "                        self.coef, _ = curve_fit(polyfunc, pointy, np.array(pointx), p0=self.coef)\n",
    "                    centerx_current = int(np.polyval(self.coef, (window + 1) * self.window_height))\n",
    "                    curve_compute += 1\n",
    "                else:\n",
    "                    centerx_current = self.lane.previous_centers[window - self.window_offset]\n",
    "            self.max_gap = max(self.max_gap, gap)\n",
    "            leftx_current = int(centerx_current - self.lane.width / 2)\n",
    "            rightx_current = int(centerx_current + self.lane.width / 2)\n",
    "        if not self.lane_change:\n",
    "            if self.max_gap > self.max_gap_th and self.count > 0:\n",
    "                self.lane.left_windows = []\n",
    "                self.lane.right_windows = []\n",
    "                self.message += \"SKIPPED  \" + str(self.max_gap)\n",
    "                self.count += 1\n",
    "                self.n_gap_skip += 1\n",
    "                self.compute_bounds(cv2.cvtColor(pp_img, cv2.COLOR_BGR2HLS))\n",
    "                return warped_img\n",
    "            status, message = self.lane.addlane(pointy, np.array(pointx))\n",
    "            self.message += message\n",
    "            if not status:\n",
    "                self.compute_bounds(cv2.cvtColor(pp_img, cv2.COLOR_BGR2HLS))\n",
    "            else:\n",
    "                self.lane.compute_curvature(self.px_per_ym, self.px_per_xm)\n",
    "        self.count += 1\n",
    "        return warped_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "# if __name__ == \"__main__\":\n",
    "\n",
    "\n",
    "    bbox = (0, 40, 1280,720)\n",
    "    fps = 30\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            screen = np.array(ImageGrab.grab(bbox=bbox))\n",
    "            image = cv2.cvtColor(screen, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Process the frame with your lane detection\n",
    "            ld = LANE_DETECTION(image, fps, \n",
    "                                yellow_lower=np.uint8([20, 50, 110]),\n",
    "                                yellow_upper=np.uint8([35, 255, 255]),\n",
    "                                white_lower=np.uint8([0, 140, 0]), \n",
    "                                white_upper=np.uint8([255, 255, 100]), \n",
    "                                lum_factor=110,\n",
    "                                lane_start=[0.2, 0.5])\n",
    "            processed_frame = ld.process_image(image)\n",
    "\n",
    "            # Display the processed frame on the monitor\n",
    "            cv2.imshow('Lane Detection', processed_frame)\n",
    "\n",
    "            # Exit if 'q' is pressed\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Video processing stopped by user\")\n",
    "    finally:\n",
    "        # Release resources and close all OpenCV windows\n",
    "        cv2.destroyAllWindows()\n",
    "        print(\"Resources released and video processing completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABSURD X POSITION TRY OTHER PARAMETERS 419.06592 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\motoko\\AppData\\Local\\Temp\\ipykernel_17972\\1499348140.py:84: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  self.current_coef, _ = curve_fit(polyfunc, self.y, self.x, p0=self.smoothed_poly)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABSURD X POSITION TRY OTHER PARAMETERS 419.06592 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 419.06592 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 419.06592 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 419.06592 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 419.06592 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 419.06592 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 465.7773 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 569.0843 in ==>  (680, 1280)\n",
      "76\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "76\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 569.0843 in ==>  (680, 1280)\n",
      "76\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "76\n",
      "No lines detected\n",
      "NO VANISHING POINT DETECTED\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 374.62775 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 380.0519 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 376.0158 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 359.64395 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 308.1935 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 394.1661 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 300.064 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 320.2639 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 370.23132 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 304.98944 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 281.081 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 318.80597 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 391.8086 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 382.88123 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 343.63193 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 351.13455 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 401.56555 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 389.5737 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 382.998 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 360.75522 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 373.05536 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 347.5068 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 350.9594 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 369.2966 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 369.81644 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 341.6013 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 340.93198 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 340.52438 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 338.10147 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 277.37982 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 390.2213 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 381.60306 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 373.67987 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 413.20197 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 407.9787 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 421.17926 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 374.76547 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "Error: Division by zero in compute_curvature\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\motoko\\AppData\\Local\\Temp\\ipykernel_17972\\3777286214.py:221: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  self.xm_per_px = 1 / self.px_per_xm\n",
      "C:\\Users\\motoko\\AppData\\Local\\Temp\\ipykernel_17972\\3777286214.py:228: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  self.ym_per_px = 1 / self.px_per_ym\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABSURD X POSITION TRY OTHER PARAMETERS 386.25027 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "76\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "76\n",
      "Error: Division by zero in compute_curvature\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 407.13098 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "76\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "76\n",
      "Error: Division by zero in compute_curvature\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 419.97482 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 404.68707 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 459.4036 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 383.15372 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "76\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "76\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 438.70047 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 430.80603 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 548.3805 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 364.52277 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "76\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "76\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 397.7759 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "76\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "76\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 397.4181 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "76\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "76\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 398.49286 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "76\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "76\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 426.514 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "81\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "99\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 474.86902 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "98\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "111\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 392.1586 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "155\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "181\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 448.58948 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "174\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 395.9022 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "202\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 323.04514 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "188\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "214\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 470.2468 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "176\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "199\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 431.7883 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "212\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 430.30725 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "176\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 322.375 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "211\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 497.98843 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 399.04715 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 465.2663 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "213\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 398.51733 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "197\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 477.7211 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "207\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 545.18164 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 454.15656 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 426.59128 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 416.8239 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "194\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "171\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 385.9261 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 418.00156 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 439.4823 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 489.5071 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 441.0329 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 479.37994 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 491.749 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 396.4824 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 410.7053 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 332.1617 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 396.55417 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 412.9082 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "108\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "117\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 361.31274 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "142\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "144\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 385.27838 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "106\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "91\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 417.33722 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 443.0448 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 493.71204 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 361.8362 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 437.72025 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 373.45538 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 434.04828 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 487.31262 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 420.50223 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 426.88058 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 480.20605 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 398.03058 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "99\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "90\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 389.02225 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 402.95624 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "76\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "76\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 426.70435 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 376.0938 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "76\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "76\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 448.54147 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 470.52826 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 463.59958 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 438.0521 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 440.26413 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 411.5307 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD X POSITION TRY OTHER PARAMETERS 506.3282 in ==>  (680, 1280)\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 640.0 in ==>  (680, 1280)\n",
      "221\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "221\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 559.57697 in ==>  (680, 1280)\n",
      "76\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "76\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 567.80225 in ==>  (680, 1280)\n",
      "76\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "76\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 567.80225 in ==>  (680, 1280)\n",
      "76\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "76\n",
      "ABSURD Y POSITION TRY OTHER PARAMETERS 567.80225 in ==>  (680, 1280)\n",
      "76\n",
      "PERSPECTIVE TRANSFORMATION MATRIX COMPUTED\n",
      "76\n",
      "Resources released and video processing completed.\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GTA5AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
